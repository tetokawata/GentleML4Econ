{
  "hash": "c7912a9dd10e09a8de7b335f2f3604a8",
  "result": {
    "engine": "knitr",
    "markdown": "# 予測モデルの推定 {#sec-Prediction}\n\n## 現実\n\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    newrank=true;\n    \n    node[shape = none, fontsize=\"8pt\"];\n    edge[arrowsize = 0.1, fontsize = \"8pt\"];\n    \n    X [label = \"X\"]\n    Y [label = \"Y\"]\n    f_Y [label = \"「未知の」メカニズム\"]\n    X -> f_Y ->Y\n    {rank=same; X; f_Y; Y}\n}\n```\n\n\n## ML\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    newrank=true;\n    \n    node[shape = none, fontsize=\"8pt\"];\n    edge[arrowsize = 0.1, fontsize = \"8pt\"];\n    \n    X [label = \"X\"]\n    Y [label = \"Y\"]\n    f_Y [label = \"「未知の」メカニズム\"]\n    g_Y [label = \"複雑なモデル\"]\n    Est [label = \"推定\"]\n    X -> f_Y -> Y\n    X -> g_Y -> Y\n    f_Y -> g_Y [label = \"近似\"]\n    g_Y -> Est [dir = \"back\"]\n    {rank=same; X; f_Y; Y}\n}\n```\n\n\n\n## Getting Started\n\n\n::: {.cell}\n\n:::\n\n\n## 予測問題\n\n- 定義: 欠損情報 $Y$ を、観察できる変数 $X$ から予測するモデル $g(X)$ を構築する\n\n    - 視聴履歴やいいね数 $(X) \\rightarrow$ 好む未視聴動画 $(Y)$\n    \n    - メールの文名や件名 $(X) \\rightarrow$ 迷惑メール $(Y)$\n    \n    - 事業の内容や財務状況 $(X) \\rightarrow$ デフォルトリスク $(Y)$\n\n- $Y,X$ が共に観察できるデータを活用できれば、推定方法がある程度確立されている (教師付き学習)\n\n## アイディア\n\n- 過去の $Y-X$ の間の定量的なパターンを、データから抽出し、予測に利用する\n\n    - 「1平米広い部屋は100万円高い価格で取引されがち」など\n    \n        - そのデータ上にのみ偶然現れたパターンに注意する\n\n- 予測の対象となる新しい事例と過去の事例(データ)との間に、一貫性が必要\n\n## データ分割による評価\n\n- 予測モデルの性能をどのように評価するか\n\n    - 実際に実装し、運用すれば、そのうち性能がわかるが...\n    \n        - 遅すぎる場合も多い\n\n- データをランダム２分割(Training/Test)に分割し、Trainingデータのみでモデルを作り、Testで評価する\n\n- 典型的には、Testデータについて、平均二乗誤差 $$(Y - 予測値)^2の平均値$$\n\n## イメージ\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    node[shape = none fontsize = \"10pt\"]\n    Original [label = \"データ\"]\n    Data [label = \"訓練データ {Y,X}\"]\n    New [label = \"テストデータ {Y,X}\"]\n    Model [label = \"予測モデル g(X)\"]\n    Predict [label = \"予測値 Y^*\"]\n    Original -> Data [arrowsize=0.3 fontsize = \"10pt\" label = \"ランダム分割\"]\n    Original -> New [arrowsize=0.3]\n    Data -> Model [arrowsize=0.3 label = \"推定\"]\n    New -> Model -> Predict [arrowsize=0.3]\n    Predict -> New [arrowsize=0.3 label = \"テスト\" fontsize = \"10pt\"]\n    {rank=same; Data; New}\n    {rank=same; Predict; Model}\n}\n```\n\n\n## 典型的誤解\n\n- 機械学習を用いて推定すれば、予測性能が高いモデルが獲得できる\n\n- 複雑な現象を予測するためには、複雑なモデルの方が望ましい\n\n- Big dataを用いれば、理想的な予測モデルを推定できる\n\n- 予測性能が悪いモデルは、役に立たない\n\n\n## 母集団を用いた整理\n\n- 母集団: 論点整理を目的とした**概念**\n\n## 母集団\n\n- 手元のデータに含まれる事例は、母分布(集団)から抽出されたと想定する\n\n    - 本講義では、ランダムに選ばれるケースに集中する\n    \n        - Random Sampling\n    \n    - 予測対象も、母分布からランダムに選ばれるとする\n\n- 一般にデータと母分布は、完全一致しない\n\n## 例\n\n- ユーザーの需要調査(どのようなサービスを望むか)\n\n    - データ: サービス利用者の中からランダムに選ばれた200名 (例: 20代が2割)\n    \n        - 母集団: 全サービス利用者 (例: 20代が2.2割)\n        \n        - 予測対象: $X$ (年齢など)のみ判明している利用者\n\n- 不動産取引価格の予測モデル\n\n    - データ: 2022年第二四半期のすべての取引事例\n    \n        - 母集団: 潜在的な全取引\n        \n        - 予測対象: まだ取引されていない物件\n\n## イメージ\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    node[shape = none fontsize=\"10pt\"];\n    Population [label = \"母集団: 無数の事例 {Y,X}\"]\n    Data [label = \"データ {Y,X}\"]\n    New [label = \"新しい事例 {?,X}\"]\n    Model [label = \"予測モデル g(X)\" ]\n    Predict [label = \"予測値 Y^*\"]\n    Population -> Data [arrowsize=0.3 label = \"ランダム抽出\" fontsize = \"8pt\"]\n    Data -> Model [arrowsize=0.3]\n    Population -> New -> Model -> Predict [arrowsize=0.3 color = \"red\"]\n    {rank=same; Data; New}\n    {rank=same; Model; Predict}\n}\n```\n\n\n## 数値例: データ\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## 数値例: 予測モデル\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n## 数値例: 予測モデル\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## 数値例: 予測モデルと母平均\n\n- ここから想像の世界\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n## 不透明性 (Uncertainly)\n\n- データ分析を含む事例分析の一般的課題\n\n    - 独立した分析チームに**同じ市場/社会**の分析を依頼したとしても、同じ結論に到達し得ない\n    \n        - 誰がやっても、「水は100度で沸騰する」という結論を再現できる理科の実験とは対照的\n    \n## Sampling / Model Uncertainly\n\n- 観察する事例が人によって異なる (**Sampling uncertainly**)\n\n    - 伝統的なデータ分析における主たる関心\n\n- 事例の要約方法(モデル化)が属人的で、不透明 (**Model uncertainly**)\n\n    - 多くの教科書で直接的な言及を避けてきた問題\n    \n        - 「理論や背景をしっかり踏まえて、適切なモデル化を行うべし」以上の提案が難しい\n\n## Sampling Uncertainlyの軽減\n\n- 問題: データから観察できない価格決定要因の\"偏り\"が、データ固有の特徴を生み出す\n\n- 対策: 多くの事例を集計(モデル化)し、傾向把握を行う\n\n    - 初歩的な方法: よく似た労働者も高賃金を得ているか確認する\n\n\n## 機械学習の利点\n\n- 決定木を含む機械学習の手法は、明確な記述に基づくデータ主導のモデル化を行う\n\n    - Model Uncertainlyが軽減される\n\n## 機械学習の問題点\n\n- データ主導のモデル生成は、Sampling uncertainlyを\"複雑化\"する\n\n    - データに応じてモデルが大きく変化しうるため\n    \n- 伝統的な理論的性質(中心極限定理など)が適用できず、信頼区間などが近似計算できない\n\n    - $Y$ に近い値を得ることが目標である予測問題では、通常大きな問題にならない\n    \n    - むしろモデル全体の予測性能を評価することが重要\n\n\n## 数値例: 決定木\n\n- 4名の分析者(ID 1-4) が独立してデータを収集し、決定木でモデルを推定したとすると、\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## 数値例: Size $= 40$ で分割\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n- データとは無関係に、size = 40 で予測値が\"誤って\"変化する\n\n\n## モデルの評価\n\n## 予測モデルの評価: 理想編\n\n- どんな予測もまぐれあたりしうる\n\n    - 平均的にうまく行くモデルを採用したい\n    \n- 予測モデルを母分布に適用して評価する: 典型的には二乗誤差の母平均値を用いる $E[(Y - g(X))^2]$\n\n## 予測モデルの評価: 現実編\n\n- 母分布は観察できないので、母分布に適用した際の予測性能は\"推定する必要\"がある\n\n    - 母分布からランダムに選ばれた事例でテストしたい\n\n- 最も典型的な評価法は、データ分割: データをランダムに2分割 (訓練/テストデータ)し、訓練データのみでモデルを推定し、テストデータで評価\n\n## イメージ\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    node[shape = box];\n    Population [label = \"母集団: 無数の事例 {Y,X}\" shape = none fontsize=\"10pt\"]\n    Original [label = \"データ\" shape = none fontsize = \"10pt\"]\n    Data [label = \"訓練データ {Y,X}\" shape = none fontsize = \"10pt\"]\n    New [label = \"テストデータ {Y,X}\" shape = none fontsize = \"10pt\"]\n    Model [label = \"予測モデル g(X)\" shape = none fontsize = \"10pt\"]\n    Predict [label = \"予測値 Y^*\" shape = none fontsize = \"10pt\"]\n    Population -> Original [arrowsize = 0.3 fontsize = \"10pt\" label = \"ランダム抽出\"]\n    Original -> Data [arrowsize=0.3 fontsize = \"10pt\" label = \"ランダム分割\"]\n    Original -> New [arrowsize=0.3]\n    Data -> Model [arrowsize=0.3]\n    New -> Model -> Predict [arrowsize=0.3 color = \"red\"]\n    Predict -> New [arrowsize=0.3 color = \"red\" label = \"テスト\" fontsize = \"10pt\"]\n    {rank=same; Population; Original}\n    {rank=same; Data; New}\n    {rank=same; Predict; Model}\n}\n```\n\n\n\n## 補論: モデルを使い続けられるか?\n\n- モデル推定に用いるデータの母分布と、予測対象の母分布が異なれば、予測性能は悪化する\n\n    - 高性能モデルでも、時代の変化/大きな社会的ショックの発生等の結果、性能が悪化しうる\n    \n        - 通常の設備と同様に、経年劣化/破壊されうる\n\n- 定期的に予測性能を計り直し、再推定する必要がある\n\n    - Concept-Driftと呼ばれる\n\n## 極端なモデルの推定\n\n- 予測モデルの推定の原理を理解するために、極端な推定方法で何が生じるのか理解する\n\n## 理想の予測モデル\n\n- もし**母集団**をすべて活用して、モデル推定できるのであれば、理想の予測モデルは母平均 $E[Y|X]$\n\n    - 予測誤差を平均二乗誤差で測定するのが前提\n\n- 「各グループ内での平均的傾向」よりも優れた予測は**あり得ない**\n\n## 完璧な予測は可能か?\n\n- 予測不可能な部分 $Y - E[Y|X]$ が発生\n\n    - 削減不可能な誤差\n    \n- 予測対象となる母集団(社会)、$Y/X$ が決まった時点で自動的に定まる\n\n    - $X$ 内で個人差がある現象の予測は難しい\n\n        - 人間行動やその相互作用で決まる現象 (例: 消費、貯蓄、出生、就業、賃金、等)は大きい傾向\n\n## 予測モデルの推定: 現実\n\n- 母集団は観察できないので、データで置き換える必要がある\n\n    - 単純なモデルを推定すると、母平均の複雑さを捉えられない\n    \n    - 複雑なモデルを推定すると、データが偶然持った特徴を母平均の特徴と混同してしまう\n\n## 現実的な方法: 単純平均法\n\n- 単純な平均取引価格を予測値とする\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## 現実的な方法: 丸暗記法\n\n- 各$X$ について、データ上の平均値を予測値とする\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## 複雑なモデルは望ましいのか?\n\n- 丸暗記モデルは非常に複雑なモデルを生み出し、望ましいように思える\n\n    - 現実は複雑\n    \n    - **推定に用いた**データとの矛盾はない\n    \n        - 予測値とデータ上の平均値は、必ず一致する\n\n- **一般に予測性能は極めて悪い**\n\n    - 少数の事例のみで計算れた平均値は、$X$ 以外の決定要因の偏りを反映してしまう\n\n## 補論: 丸暗記が有効な場合\n\n- $X$ 以外に $Y$ の決定要因がなければ、丸暗記は有効\n    \n    - 例: 判例予測、コンピュータの動作予測\n    \n- 人間行動については、$X$ 以外の無数の決定要因が存在\n        \n    - 例: \"双子\"でも違う人生を歩む\n\n    - 丸暗記に向いていない\n\n## 中庸なモデルの推定\n\n- 多くの応用で平均値は単純すぎ、丸暗記は複雑すぎる\n\n- 決定木については、最大分割回数などを変更することで、単純平均と丸暗記法の間を移行できる\n\n\n\n## モデル選択/集計\n\n- 決定木の深さが異なれば、予測モデルは異なる\n\n- 複数のモデルを\"試作\"し、予測性能を測定、最も性能が良いモデルを選ぶのは一つの方法\n\n- 決定木については、複数のモデルを試作し、その予測結果を集計することがより有効な場合が多い\n\n    - モデル集計/アンサンブル法などと呼ばれる\n\n## 概要\n\n- 複雑なモデルを推定すると、母平均から大きく乖離した事例(ハズレ値)の影響を強く受ける\n  \n    - 予測結果を安定されるために、大量の予測モデルを作り、その平均値を最終予測とすることが有効 (Bagging)\n    \n    - 一部の変数の使用を確率的に禁止することも併用できる (RandomForest)\n    \n## イメージ: Bagging\n\n- Bootstrap法を用いて、予測モデルを大量に作る (500-5000個程度)\n\n\n```{dot}\ndigraph {\n    rankdir=TB;\n    node[shape = box];\n    Data [label = \"訓練データ\\n[Y={10,2,4},X={5,7,1}]\" shape = none fontsize = \"10pt\"]\n    Boot1 [label = \"複製データ1\\n[Y={2,2,4},X={7,7,1}]\" shape = none fontsize = \"10pt\"]\n    Boot2 [label = \"複製データ2\\n[Y={10,2,2},X={5,7,7}]\" shape = none fontsize = \"10pt\"]\n    Boot3 [label = \"複製データ3\\n[Y={10,10,4},X={5,5,1}]\" shape = none fontsize = \"10pt\"]\n    Model1 [label = \"予測モデル1 \\ng1(X)\" shape = none fontsize = \"10pt\"]\n    Model2 [label = \"予測モデル2 \\ng2(X)\" shape = none fontsize = \"10pt\"]\n    Model3 [label = \"予測モデル3 \\ng3(X)\" shape = none fontsize = \"10pt\"]\n    Summary [label = \"平均\" shape = none fontsize = \"10pt\"]\n    Prediction [label = \"最終予測\" shape = none fontsize = \"10pt\"]\n    Data -> Boot1 -> Model1\n    Data -> Boot2 -> Model2\n    Data -> Boot3 -> Model3\n    Model1 -> Summary\n    Model2 -> Summary\n    Model3 -> Summary\n    Summary -> Prediction\n}\n```\n\n\n\n\n## RandomForest の利点\n\n- Bootstrapは、\"ハズレ値\"を含まないデータとそれを用いたモデルも生成される\n\n    - ハズレ値の影響を軽減できる\n    \n- 変数の一部を確率的に使用できなくすることで、モデル間で用いる変数の多様性が促進される\n\n    - より多くの変数の情報が活用できる\n\n- 注: 実際にはモデル単位ではなく、サンプル分割ごとに、(元々の変数数のsquare root個)ランダムに使用禁止する\n\n## 数値例: Random Forest\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n## Big dataは優れた予測モデルを保証するか?\n\n- 「Big data $=$ サンプルサイズが多い」、のであれば、完璧な予測モデル $g(X) = Y$ を保証しない\n\n    - 削減不可能な誤差 $Y - E[Y|X]$ が存在するため\n    \n- 理想的な予測モデル $g(X) = E[Y|X]$ は保証できるか?\n\n    - 伝統的な方法 $=$ 極めて強い仮定のもとでのみ可能\n\n    - 多くの機械学習 $=$ 緩やかな仮定で可能\n\n## 数値例: 伝統的アプローチ(5000事例)\n\n- 研究者が、「Size $= 40$ で分割する」と決定\n\n    - 推定されうるモデルを限定する\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n## 数値例: Random Forest with large sample (5000事例)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](prediction_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## まとめ\n\n- 実際/理想/完璧な予測モデルの区別が重要\n\n- 理想の予測モデル: $g(X)=E[Y|X]$\n\n    - 個人差があれば、完璧な予測 $g(X)=Y$ は不可能\n    \n- 限られたデータから推定されたモデルは、理想の予測モデルとはならない $g(X)\\neq E[Y|X]$\n\n    - 機械学習を用いて、近づけることは可能\n\n- 予測に使う前に、テストデータを用いた性能調査が必須\n\n## Reference",
    "supporting": [
      "prediction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}